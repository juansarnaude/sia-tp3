{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c665a4fe49d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperceptrons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiLayerPerceptron\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiLayerPerceptron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientDescent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMomentum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMomentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.metrics.Evaluator import Evaluator\n",
    "from src.perceptrons.MultiLayerPerceptron import MultiLayerPerceptron\n",
    "from src.optimizer.GradientDescent import GradientDescent\n",
    "from src.optimizer.Momentum import Momentum\n",
    "from src.optimizer.Adam import Adam\n",
    "from src.utils.functions import sigmoid, tanh, gaussian_noise, index_of_max_value\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"./configs/ej3c.json\") as file:\n",
    "    config = json.load(file)\n",
    "\n",
    "    df = pd.read_csv(config[\"input_file\"], delimiter=' ', header=None)\n",
    "\n",
    "    df = df.iloc[:, :-1]\n",
    "\n",
    "    matrix_list = [df.iloc[i:i + 7, :] for i in range(0, len(df), 7)]\n",
    "\n",
    "    flattened_matrixes = [matrix.values.flatten() for matrix in matrix_list]\n",
    "\n",
    "    learning_rate=config[\"learning_rate\"]\n",
    "\n",
    "    # layers per output\n",
    "    layer_sizes=config[\"layer_sizes\"]\n",
    "\n",
    "    # activation_function\n",
    "    activation_function_str = config[\"activation_function\"]\n",
    "    if activation_function_str == \"tanh\":\n",
    "        activation_funciton = tanh\n",
    "    elif activation_function_str == \"sigmoid\":\n",
    "        activation_funciton = sigmoid\n",
    "    else:\n",
    "        raise ValueError(\"invalid activation function argument\")\n",
    "    \n",
    "    # Optimizer configuration\n",
    "    optimizer_config = config[\"optimizer\"]\n",
    "\n",
    "    optimizer_str = optimizer_config[\"method\"]\n",
    "    momentum = optimizer_config[\"momentum\"]\n",
    "\n",
    "    adam_config = optimizer_config[\"adam\"]\n",
    "    beta_1 = adam_config[\"beta_1\"]\n",
    "    beta_2 = adam_config[\"beta_2\"]\n",
    "\n",
    "    optimizer = None\n",
    "    if optimizer_str == \"gradient_descent\":\n",
    "        optimizer = GradientDescent(learning_rate)\n",
    "    elif optimizer_str == \"momentum\":\n",
    "        optimizer = Momentum(learning_rate, momentum)\n",
    "    elif optimizer_str == \"adam\":\n",
    "        optimizer = Adam(learning_rate, beta_1, beta_2)\n",
    "    else:\n",
    "        raise ValueError(\"invalid optimizer method argument\")\n",
    "\n",
    "    # cutoffs\n",
    "    epochs = config[\"epochs\"]\n",
    "    epsilon = config[\"epsilon\"]\n",
    "\n",
    "    # list of inputs\n",
    "    inputs = flattened_matrixes\n",
    "\n",
    "    mlp = MultiLayerPerceptron(\n",
    "        layer_sizes=layer_sizes,\n",
    "        activation_function=activation_funciton,\n",
    "        optimizer=optimizer\n",
    "    )\n",
    "\n",
    "    training_expected_values = [\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
    "  ]\n",
    "    \n",
    "    testing_expected_values = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "    evaluator = Evaluator(10, 10, 0.00001, index_of_max_value)\n",
    "\n",
    "    accuracy, f1, precision, recall = evaluator.evaluate(mlp, inputs, training_expected_values, inputs, testing_expected_values, 1000)\n",
    "\n",
    "    print(f\"accuracy: {accuracy}\\nf1: {f1}\\nrecall: {recall}\\nprecision: {precision}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
